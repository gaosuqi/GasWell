{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import tft_model\n",
    "import ts_dataset\n",
    "import expt_settings.configs\n",
    "import importlib\n",
    "from data_formatters import utils\n",
    "import torch\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentConfig = expt_settings.configs.ExperimentConfig\n",
    "config = ExperimentConfig('gas_production', 'outputs')\n",
    "data_formatter = config.make_data_formatter()\n",
    "data_csv_path = config.data_csv_path\n",
    "test_csv_path = os.path.join(config.data_folder, 'GasProductionTFTTest.csv')\n",
    "train_csv_path = os.path.join(config.data_folder, 'GasProductionTFTTrain.csv')\n",
    "valid_csv_path = os.path.join(config.data_folder, 'GasProductionTFTValid.csv')\n",
    "\n",
    "raw_data = pd.read_csv(data_csv_path, index_col=0)\n",
    "train = pd.read_csv(train_csv_path)\n",
    "valid = pd.read_csv(valid_csv_path)\n",
    "test = pd.read_csv(test_csv_path)\n",
    "# Sets up default params\n",
    "data_formatter.set_scalers(train, set_real=True)\n",
    "# Use all data for label encoding  to handle labels not present in training.\n",
    "data_formatter.set_scalers(raw_data, set_real=False)\n",
    "test_transformed = data_formatter.transform_inputs(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params = data_formatter.get_experiment_params()\n",
    "params = data_formatter.get_default_model_params\n",
    "\n",
    "fixed_params.update(params)\n",
    "fixed_params['batch_first'] = True\n",
    "fixed_params['name'] = 'test'\n",
    "fixed_params['device'] = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "fixed_params['minibatch_size'] = 256\n",
    "fixed_params['quantiles'] = [0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_time_steps': 35, 'num_encoder_steps': 28, 'num_epochs': 100, 'early_stopping_patience': 5, 'multiprocessing_workers': 5, 'column_definition': [('WellNo', <DataTypes.CATEGORICAL: 1>, <InputTypes.ID: 4>), ('Date', <DataTypes.DATE: 2>, <InputTypes.TIME: 5>), ('Daily_104m3', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('WellHeadPressure', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('CasingHeadPressure', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('WellHeadTemperature', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('Daily_h', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('Elapsed', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('ElapsedProduction', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('Allocation', <DataTypes.REAL_VALUED: 0>, <InputTypes.STATIC_INPUT: 3>), ('Cluster', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>)], 'input_size': 9, 'output_size': 1, 'category_counts': [9], 'input_obs_loc': [0], 'static_input_loc': [7, 8], 'known_regular_inputs': [4, 5, 6, 7], 'known_categorical_inputs': [0], 'inputs_encoder': ['Daily_104m3', 'WellHeadPressure', 'CasingHeadPressure', 'WellHeadTemperature', 'Daily_h', 'Elapsed', 'ElapsedProduction', 'Allocation', 'Cluster'], 'inputs_decoder': ['Daily_h', 'Elapsed', 'ElapsedProduction', 'Allocation', 'Cluster'], 'dropout_rate': 0.1, 'hidden_layer_size': 240, 'learning_rate': 0.001, 'minibatch_size': 256, 'max_gradient_norm': 100.0, 'num_heads': 4, 'stack_size': 1, 'batch_first': True, 'name': 'test', 'device': device(type='cpu'), 'quantiles': [0.5]}\n",
      "_known_regular_input_idx:[4, 5, 6, 7], _known_categorical_input_idx:[0], num_static: 2, num_inputs:7\n",
      "num_categorical_variables\n",
      "1\n",
      "input_size:28, num_inputs:7, hidden_layer_size:240\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9688\\477575757.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtft_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfixed_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfixed_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'device'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'gas_production_best_model_loss.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1618\u001b[0m         \"\"\"\n\u001b[0;32m   1619\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1620\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expected state_dict to be dict-like, got {}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m         \u001b[0mmissing_keys\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class 'str'>."
     ]
    }
   ],
   "source": [
    "model = tft_model.TFT(fixed_params).to(fixed_params['device'])\n",
    "model.load_state_dict(config.model_folder + '/gas_production_best_model_loss.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ts_dataset.TSDataset(fixed_params, test_transformed, num_samples=-1)\n",
    "test_loader = DataLoader(\n",
    "            test_ds,\n",
    "            batch_size=fixed_params['minibatch_size'],\n",
    "            num_workers=4,\n",
    "            shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for idx, batch in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output, all_inputs, attention_components = model(batch['inputs'])\n",
    "        flat_prediction = pd.DataFrame(\n",
    "          output.detach().cpu().numpy()[:, :, 0],\n",
    "          columns=[\n",
    "              't+{}'.format(i)\n",
    "              for i in range(18)\n",
    "          ])\n",
    "        cols = list(flat_prediction.columns)\n",
    "#         flat_prediction['forecast_time'] = batch['time'][:, 54 - 1, 0]\n",
    "        flat_prediction['identifier'] = batch['identifier'][0][0].detach().cpu().numpy()\n",
    "        dfs.append(flat_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_unnormalized = data_formatter.format_predictions(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_unnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_mean_absolute_percentage_error(forecast, actual):\n",
    "    # Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "    return np.mean(2 * np.abs(forecast - actual) / (np.abs(actual) + np.abs(forecast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = pd.read_csv('/home/arda/Desktop/thesis/datasets/m4/Test/Monthly-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(actuals.drop(columns=['V1']).values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(all_predictions_unnormalized.drop(columns=['identifier']).values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetric_mean_absolute_percentage_error(np.concatenate(all_predictions_unnormalized.drop(columns=['identifier']).values) ,np.concatenate(actuals.drop(columns=['V1']).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ind = np.random.choice(128)\n",
    "print(ind)\n",
    "plt.plot(output[ind,:,1].detach().cpu().numpy(), label='pred')\n",
    "# plt.plot(output[ind,:,1].detach().cpu().numpy(), label='pred_5')\n",
    "# plt.plot(output[ind,:,2].detach().cpu().numpy(), label='pred_9')\n",
    "\n",
    "plt.plot(batch['outputs'][ind,:,0], label='true')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
